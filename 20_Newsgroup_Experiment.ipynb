{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import ssnmf\n",
    "from multi_nmf import run_HNMF_unsupervised_single, run_HNMF_supervised_single\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "from ssnmf import SSNMF\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocessing for 20 Newsgroup Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ('headers','footers','quotes')\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list.extend(['thanks','edu','also','would','one','could','please','really','many','anyone','good','right','get','even','want','must','something','well','much','still','said','stay','away','first','looking','things','try','take','look','make','may','include','thing','like','two','or','etc','phone','oh','email'])\n",
    "\n",
    "\n",
    "categories = [\n",
    " 'comp.graphics',\n",
    "\n",
    " 'comp.sys.mac.hardware',\n",
    " 'misc.forsale',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.religion.misc'\n",
    " ]\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
    "\n",
    "# remove numbers\n",
    "data_cleaned = [re.sub(r'\\d+','', file) for file in newsgroups_train.data]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_list)\n",
    "vectors = vectorizer.fit_transform(data_cleaned).transpose()\n",
    "idx_to_word = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "X = vectors\n",
    "d, n = np.shape(X)\n",
    "Y = np.zeros((n))\n",
    "\n",
    "labels = {0:0, 1:0, 2:1, 3:2, 4:2, 5:3, 6:3, 7:4, 8:4, 9:5}\n",
    "\n",
    "for i in range(n-1):\n",
    "    label = newsgroups_train.target[i]\n",
    "    Y[i] = label\n",
    "\n",
    "X = torch.from_numpy(X.todense())\n",
    "Y = torch.from_numpy(Y).long()\n",
    "\n",
    "\n",
    "m = X.shape[0]\n",
    "k1 = 10\n",
    "k2 = 6\n",
    "\n",
    "sub = 100 #HOW MANY PER CLASS\n",
    "count = np.zeros((k1))\n",
    "\n",
    "X_new = torch.zeros((X.shape[0], sub*k1))\n",
    "Y_new = torch.zeros((sub*k1)).long()\n",
    "Y_10 = torch.zeros((sub*k1)).long()\n",
    "j = 0\n",
    "for i in range(Y.shape[0]):\n",
    "    if(count[Y[i]] >= sub):\n",
    "        continue\n",
    "    count[Y[i]] += 1\n",
    "    X_new[:,j] = X[:,i]\n",
    "    Y_new[j] = labels[int(Y[i])]\n",
    "    Y_10[j] = int(Y[i])\n",
    "    j += 1\n",
    "\n",
    "X = X_new\n",
    "Y = Y_new\n",
    "\n",
    "ind = np.argsort(Y_10)\n",
    "X = X[:,ind]\n",
    "Y = Y[ind]\n",
    "Y_10 = Y_10[ind]\n",
    "\n",
    "split = 0.75\n",
    "L = np.zeros((6, Y.shape[0]))\n",
    "for i in range(10):\n",
    "    L[:,i*sub:i*sub+(int(split*sub))] = 1\n",
    "    \n",
    "L_10 = np.zeros((10, Y.shape[0]))\n",
    "for i in range(10):\n",
    "    L_10[:,i*sub:i*sub+(int(split*sub))] = 1\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "Y_10 = np.asarray(Y_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hot = np.zeros((Y.shape[0], Y.max()+1))\n",
    "Y_hot[np.arange(Y.shape[0]),Y] = 1\n",
    "Y_hot = Y_hot.T\n",
    "\n",
    "Y_hot_10 = np.zeros((Y_10.shape[0], Y_10.max()+1))\n",
    "Y_hot_10[np.arange(Y_10.shape[0]),Y_10] = 1\n",
    "Y_hot_10 = Y_hot_10.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run HNMF and Multi-HNTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with run...    1\n",
      "Done with run...    2\n",
      "Done with run...    3\n",
      "Done with run...    4\n",
      "Done with run...    5\n",
      "Done with run...    6\n",
      "Done with run...    7\n",
      "Done with run...    8\n",
      "Done with run...    9\n",
      "Done with run...    10\n"
     ]
    }
   ],
   "source": [
    "results_all_layer_1 = []\n",
    "results_all_layer_1_sup = []\n",
    "results_all_layer_2_unsup = []\n",
    "results_all_layer_2_sup = []\n",
    "\n",
    "results_all_layer_2_Hunsup = []\n",
    "results_all_layer_2_Hsup = []\n",
    "\n",
    "lam = 1\n",
    "N = 800\n",
    "num_trials = 10\n",
    "\n",
    "for i in range(num_trials):\n",
    "    \n",
    "    # Run First Layer of Unsupervised NMF\n",
    "    # ------------------------------------\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    model_1 = SSNMF(X,10,modelNum=1)\n",
    "    model_1.mult(numiters = N)\n",
    "\n",
    "    results_layer_1 = {}\n",
    "    results_layer_1['A'] = model_1.A\n",
    "    results_layer_1['S'] = model_1.S\n",
    "    results_all_layer_1.append(results_layer_1)\n",
    "    \n",
    "    # Run First Layer of Supervised NMF\n",
    "    # ------------------------------------\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    model_1_sup = SSNMF(X,10,Y = Y_hot_10,L=L_10,lam=lam,modelNum=3)\n",
    "    model_1_sup.mult(numiters = N)\n",
    "\n",
    "    results_layer_1_sup = {}\n",
    "    results_layer_1_sup['A'] = model_1_sup.A\n",
    "    results_layer_1_sup['S'] = model_1_sup.S\n",
    "    results_all_layer_1_sup.append(results_layer_1_sup)\n",
    "    \n",
    "    \n",
    "    # Run Second Layer of Unsupervised NMF\n",
    "    # ------------------------------------\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    model_2 = SSNMF(model_1.S,6,modelNum=1)\n",
    "    model_2.mult(numiters = N)\n",
    "    \n",
    "    results_layer_2_unsup = {}\n",
    "    results_layer_2_unsup['A_local'] = model_2.A\n",
    "    results_layer_2_unsup['A'] = model_1.A @ model_2.A\n",
    "    results_layer_2_unsup['S'] = model_2.S\n",
    "    results_all_layer_2_unsup.append(results_layer_2_unsup)\n",
    "    \n",
    "    \n",
    "    # Run Second Layer of Supervised NMF\n",
    "    # ------------------------------------\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    model_3 = SSNMF(model_1_sup.S,6,Y = Y_hot,L=L,lam=lam, modelNum=3)\n",
    "    model_3.mult(numiters = N)\n",
    "    \n",
    "    results_layer_2_sup = {}\n",
    "    results_layer_2_sup['A_local'] = model_3.A\n",
    "    results_layer_2_sup['A'] = model_1.A @ model_3.A\n",
    "    results_layer_2_sup['S'] = model_3.S\n",
    "    results_layer_2_sup['B'] = model_3.B\n",
    "    results_all_layer_2_sup.append(results_layer_2_sup)\n",
    "    \n",
    "    # Run Second Layer of Unspervised HNMF\n",
    "    # ------------------------------------\n",
    "    np.random.seed(i)\n",
    "    W = run_HNMF_unsupervised_single(X, model_1.A, model_1.S, 6, N=N)\n",
    "    results_layer_2_Hunsup = {}\n",
    "    results_layer_2_Hunsup['W'] = W\n",
    "    results_layer_2_Hunsup['A'] = model_1.A @ W\n",
    "    results_layer_2_Hunsup['S'] = W.T @ model_1.S\n",
    "    results_all_layer_2_Hunsup.append(results_layer_2_Hunsup)\n",
    "    \n",
    "    # Run Second Layer of Supervised HNMF\n",
    "    # ------------------------------------\n",
    "    np.random.seed(i)\n",
    "    W, B = run_HNMF_supervised_single(X, model_1_sup.A, model_1_sup.S, Y_hot * L, 6, N=N,lam=lam)\n",
    "    results_layer_2_Hsup = {}\n",
    "    results_layer_2_Hsup['W'] = W\n",
    "    results_layer_2_Hsup['B'] = B\n",
    "    results_layer_2_Hsup['A'] = model_1_sup.A @ W\n",
    "    results_layer_2_Hsup['S'] = W.T @ model_1_sup.S\n",
    "    results_all_layer_2_Hsup.append(results_layer_2_Hsup)\n",
    "    \n",
    "    print(\"Done with run...   \", i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Reconstruction Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with calculation...    1\n",
      "Done with calculation...    2\n",
      "Done with calculation...    3\n",
      "Done with calculation...    4\n",
      "Done with calculation...    5\n",
      "Done with calculation...    6\n",
      "Done with calculation...    7\n",
      "Done with calculation...    8\n",
      "Done with calculation...    9\n",
      "Done with calculation...    10\n"
     ]
    }
   ],
   "source": [
    "def get_acc(results, rank=6):\n",
    "\n",
    "    \n",
    "    if rank==6:\n",
    "        B = np.multiply(Y_hot,L) @ np.linalg.pinv(results['S'])\n",
    "        Y_pred = np.argmax(np.dot(B,results['S']), axis=0)\n",
    "        acc = Y[L[0]==0][Y_pred[L[0]==0]==Y[L[0]==0]].shape[0] / Y[L[0]==0].shape[0]\n",
    "    else:\n",
    "        B = np.multiply(Y_hot_10,L_10) @ np.linalg.pinv(results['S'])\n",
    "        Y_pred = np.argmax(np.dot(B,results['S']), axis=0)\n",
    "        acc = Y_10[L[0]==0][Y_pred[L[0]==0]==Y_10[L[0]==0]].shape[0] / Y_10[L[0]==0].shape[0]\n",
    "\n",
    "    return acc\n",
    "\n",
    "def get_recon(results):\n",
    "    return np.linalg.norm(X - results['A'] @ results['S'])\n",
    "\n",
    "acc_all_layer_1 = []\n",
    "acc_all_layer_1_sup = []\n",
    "acc_all_layer_2_unsup = []\n",
    "acc_all_layer_2_sup = []\n",
    "acc_all_layer_2_Hunsup = []\n",
    "acc_all_layer_2_Hsup = []\n",
    "\n",
    "\n",
    "recon_all_layer_1 = []\n",
    "recon_all_layer_1_sup = []\n",
    "recon_all_layer_2_unsup = []\n",
    "recon_all_layer_2_sup = []\n",
    "recon_all_layer_2_Hunsup = []\n",
    "recon_all_layer_2_Hsup = []\n",
    "\n",
    "for i in range(num_trials):\n",
    "    \n",
    "    results_layer_1 = results_all_layer_1[i]\n",
    "    results_layer_1_sup = results_all_layer_1_sup[i]\n",
    "    results_layer_2_unsup = results_all_layer_2_unsup[i]\n",
    "    results_layer_2_sup = results_all_layer_2_sup[i]\n",
    "    results_layer_2_Hunsup = results_all_layer_2_Hunsup[i]\n",
    "    results_layer_2_Hsup = results_all_layer_2_Hsup[i]\n",
    "    \n",
    "    \n",
    "    acc_all_layer_1.append(get_acc(results_layer_1))\n",
    "    acc_all_layer_1_sup.append(get_acc(results_layer_1_sup))\n",
    "    acc_all_layer_2_unsup.append(get_acc(results_layer_2_unsup))\n",
    "    acc_all_layer_2_sup.append(get_acc(results_layer_2_sup))\n",
    "    acc_all_layer_2_Hunsup.append(get_acc(results_layer_2_Hunsup))\n",
    "    acc_all_layer_2_Hsup.append(get_acc(results_layer_2_Hsup))\n",
    "    \n",
    "    recon_all_layer_1.append(get_recon(results_layer_1))\n",
    "    recon_all_layer_1_sup.append(get_recon(results_layer_1_sup))\n",
    "    recon_all_layer_2_unsup.append(get_recon(results_layer_2_unsup))\n",
    "    recon_all_layer_2_sup.append(get_recon(results_layer_2_sup))\n",
    "    recon_all_layer_2_Hunsup.append(get_recon(results_layer_2_Hunsup))\n",
    "    recon_all_layer_2_Hsup.append(get_recon(results_layer_2_Hsup))\n",
    "\n",
    "    print(\"Done with calculation...   \", i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 unsupervised accuracy...   0.5932000000000001\n",
      "Layer 1 supervised accuracy...   0.7768\n",
      "Layer 2 unsupervised accuracy...   0.5071999999999999\n",
      "Layer 2 supervised accuracy...   0.6364\n",
      "\n",
      "Layer 2 H unsupervised accuracy...   0.5159999999999999\n",
      "Layer 2 H supervised accuracy...   0.7368\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer 1 unsupervised accuracy...  \", sum(acc_all_layer_1) / num_trials)\n",
    "print(\"Layer 1 supervised accuracy...  \", sum(acc_all_layer_1_sup) / num_trials)\n",
    "\n",
    "print(\"Layer 2 unsupervised accuracy...  \", sum(acc_all_layer_2_unsup) / num_trials)\n",
    "print(\"Layer 2 supervised accuracy...  \", sum(acc_all_layer_2_sup) / num_trials)\n",
    "print()\n",
    "print(\"Layer 2 H unsupervised accuracy...  \", sum(acc_all_layer_2_Hunsup) / num_trials)\n",
    "print(\"Layer 2 H supervised accuracy...  \", sum(acc_all_layer_2_Hsup) / num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 unsupervised recon loss...   30.650902366052634\n",
      "Layer 1 supervised recon loss...   30.77671656065876\n",
      "\n",
      "Layer 2 unsupervised recon loss...   30.819847251127662\n",
      "Layer 2 supervised recon loss...   31.446235226119178\n",
      "\n",
      "Layer 2 H unsupervised recon loss...   30.81340608097356\n",
      "Layer 2 H supervised recon loss...   30.9124314614065\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer 1 unsupervised recon loss...  \", sum(recon_all_layer_1) / num_trials)\n",
    "print(\"Layer 1 supervised recon loss...  \", sum(recon_all_layer_1_sup) / num_trials)\n",
    "print()\n",
    "print(\"Layer 2 unsupervised recon loss...  \", sum(recon_all_layer_2_unsup) / num_trials)\n",
    "print(\"Layer 2 supervised recon loss...  \", sum(recon_all_layer_2_sup) / num_trials)\n",
    "print()\n",
    "print(\"Layer 2 H unsupervised recon loss...  \", sum(recon_all_layer_2_Hunsup) / num_trials)\n",
    "print(\"Layer 2 H supervised recon loss...  \", sum(recon_all_layer_2_Hsup) / num_trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
